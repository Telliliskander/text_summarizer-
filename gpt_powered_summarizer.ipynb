{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer:\n",
    "\n",
    "    # ChatGPT model that we will be using everywhere\n",
    "    openai_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "    # Constructor    \n",
    "    def __init__(self):\n",
    "        self.apikey = self.get_api_key()\n",
    "\n",
    "\n",
    "    # Method to get API key\n",
    "    def get_api_key(self):\n",
    "        # Specify the file path\n",
    "        file_path = '.env'\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(file_path):\n",
    "        # Open the file in read mode\n",
    "           with open(file_path, 'r') as file:\n",
    "           # Read the content of the file\n",
    "               content = file.read()\n",
    "\n",
    "        return content[len('OPENAI_API_KEY=')::] # in .env we have : OPENAI_API_KEY=*******\n",
    "    \n",
    "\n",
    "\n",
    "    # Method to summarize a piece of text\n",
    "    def summarize_text(self, input_text):\n",
    "        # Instantiate the client\n",
    "        client = OpenAI(api_key=self.apikey)\n",
    "\n",
    "\n",
    "        # Make request to chat GPT\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that is able to read a piece of text and summarize it as described in the prompt.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Here is the text to be summarized below the newline character.\\n {text}\".format(text=input_text)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # storing the api response in summary variable\n",
    "        summary = completion.choices[0].message.content\n",
    "\n",
    "        # Close the client\n",
    "        client.close()\n",
    "\n",
    "        return summary       \n",
    "\n",
    "\n",
    "    # Method to indentify the topic of a given text\n",
    "    def topic_identifier(self, input_text):\n",
    "\n",
    "        # Instantiate the client\n",
    "        client = OpenAI(api_key=self.apikey)\n",
    "\n",
    "        # Making the request \n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that is able to pick the topic of a given text.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Here is the text that I would like you to identify its topic, below the newline character.\\n {text}\".format(text=input_text)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # storing the api response in topic variable\n",
    "        topic = completion.choices[0].message.content\n",
    "\n",
    "        # Closing the client\n",
    "        client.close()\n",
    "\n",
    "        return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''Un grand modèle de langage (LLM) est un modèle de langage statistique, entraîné sur une grande quantité de données. Il peut être utilisé pour générer et traduire du texte et d'autres contenus, et pour effectuer d'autres tâches de traitement du langage naturel (TLN).\n",
    "Les LLM sont généralement basés sur des architectures de deep learning, comme le modèle Transformer développé par Google en 2017, et peuvent être entraînés sur des milliards de texte et d'autres contenus.\n",
    "Les LLM basés sur du texte sont utilisés pour diverses tâches de traitement du langage naturel, comme la génération de texte, la traduction automatique, la synthèse de texte, les systèmes de questions-réponses et la création de chatbots capables de tenir des conversations avec des humains.\n",
    "Les LLM peuvent également être entraînés sur d'autres types de données, y compris du code, des images, de l'audio, des vidéos, etc. Codey, Imagen et Chirp de Google sont des exemples de modèles qui permettront de lancer de nouvelles applications et de concevoir des solutions pour le les problèmes les plus difficiles du monde.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic of the text is \"Les grands modèles de langage\" (Large Language Models).\n"
     ]
    }
   ],
   "source": [
    "object = Summarizer()\n",
    "text_topic = object.topic_identifier(text)\n",
    "print(text_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les grands modèles de langage (LLM) sont des modèles de langage statistique utilisés pour générer, traduire et traiter du texte. Ils sont basés sur des architectures de deep learning, comme le modèle Transformer, et peuvent être entraînés sur de grandes quantités de données. Les LLM peuvent être utilisés dans différentes tâches de traitement du langage naturel, comme la génération de texte, la traduction automatique et la création de chatbots. Ils peuvent également être entraînés sur d'autres types de données, tels que le code, les images, l'audio et les vidéos, pour résoudre des problèmes complexes.\n"
     ]
    }
   ],
   "source": [
    "text_summary=object.summarize_text(text)\n",
    "print(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_Summarizer-CBgwxOiG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
